import os
import sys
import time
import pickle
import numpy as np
import torch
import tempfile
import webbrowser
from pathlib import Path
from werkzeug.utils import secure_filename
from flask import Flask, request, render_template, jsonify, send_file
import threading
from tqdm import tqdm

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¸Ð· Ð¾Ð±Ñ‰ÐµÐ¹ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from config import EMBEDDING_HOST, EMBEDDING_PORT, EMBEDDING_MODEL, MAX_FILE_SIZE, SUPPORTED_EXTS, CACHE_DIR, TEMP_DIR, USE_FP16, SCANNER_HOST, SCANNER_PORT
from document_processor import detect_format, extract_text, sanitize_filename
from embeddings import load_embedding_model, generate_embeddings_with_embedding_model, save_embeddings

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÐºÑÑˆÐ°
cache_processing_status = {
    'status': 'idle',  # idle, processing, completed, error
    'progress': 0,
    'current_file': '',
    'total_files': 0,
    'processed': 0,
    'result_path': '',
    'error_message': '',
    'start_time': 0,
    'end_time': 0
}

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Flask Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
app = Flask(__name__, template_folder='./templates')
app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE
app.config['UPLOAD_FOLDER'] = str(TEMP_DIR)

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ BAAI/bge-m3
print("ðŸ§  Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ BAAI/bge-m3 Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²...")
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"âš™ï¸ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ð¾Ðµ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾: {device}")
embedding_model = load_embedding_model(device)

def process_cache_embeddings_worker(cache_path, output_path):
    """Ð¤Ð¾Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð´Ð»Ñ Ð²ÑÐµÑ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð· ÐºÑÑˆÐ°"""
    global cache_processing_status
    try:
        # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÑÑˆÐ° ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        with open(cache_path, 'rb') as f:
            cache_data = pickle.load(f)
        
        if not cache_data:
            cache_processing_status.update({
                'status': 'error',
                'error_message': 'ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ÐºÑÑˆ ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ',
                'end_time': time.time()
            })
            return False
        
        texts = cache_data['texts']
        doc_paths = cache_data['doc_paths']
        
        cache_processing_status.update({
            'status': 'processing',
            'total_files': len(texts),
            'start_time': time.time(),
            'error_message': ''
        })
        
        print(f"ðŸ§  Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð´Ð»Ñ {len(texts)} Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²...")
        
        # ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°
        batch_size = 8  # Ð£Ð¼ÐµÐ½ÑŒÑˆÐ°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð° Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            if cache_processing_status['status'] != 'processing':
                print("âŒ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ñ€ÐµÑ€Ð²Ð°Ð½Ð°")
                return False
            
            batch_texts = texts[i:i+batch_size]
            batch_paths = doc_paths[i:i+batch_size]
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°
            if batch_paths:
                cache_processing_status['current_file'] = Path(batch_paths[0]).name
            cache_processing_status['processed'] = i
            cache_processing_status['progress'] = int((i / max(1, len(texts))) * 100)
            
            # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð´Ð»Ñ Ð¿Ð°ÐºÐµÑ‚Ð°
            batch_embeddings = generate_embeddings_with_embedding_model(embedding_model, batch_texts)
            all_embeddings.extend(batch_embeddings.tolist())
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        result_path = save_embeddings(output_path, doc_paths, np.array(all_embeddings))
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð¿Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸ÑŽ
        cache_processing_status.update({
            'status': 'completed',
            'end_time': time.time(),
            'result_path': str(result_path),
            'processed': len(texts),
            'progress': 100,
            'current_file': 'Ð“Ð¾Ñ‚Ð¾Ð²Ð¾'
        })
        
        print(f"âœ… Ð­Ð¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² {result_path}")
        return True
    except Exception as e:
        cache_processing_status.update({
            'status': 'error',
            'error_message': str(e),
            'end_time': time.time()
        })
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ ÐºÑÑˆÐ°: {str(e)}")
        raise

@app.route('/')
def index():
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹"""
    return render_template(
        'embedding_generator.html',
        supported_exts_single=SUPPORTED_EXTS,
        current_year=time.localtime().tm_year,
        port=EMBEDDING_PORT,
        scanner_host=SCANNER_HOST,
        scanner_port=SCANNER_PORT
    )

@app.route('/generate_embeddings', methods=['POST'])
def generate_embeddings_endpoint():
    """Ð­Ð½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð´Ð»Ñ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²"""
    if 'files' not in request.files:
        return jsonify({'error': 'Ð¤Ð°Ð¹Ð»Ñ‹ Ð½Ðµ Ð±Ñ‹Ð»Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹'}), 400
    
    files = request.files.getlist('files')
    results = []
    
    # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ñ„Ð°Ð¹Ð»Ð¾Ð²
    if not files or all(f.filename == '' for f in files):
        return jsonify({'error': 'ÐÐµ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ñ‹ Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸'}), 400
    
    for file in files:
        filename = secure_filename(file.filename)
        ext = Path(filename).suffix.lower()
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ
        if ext not in SUPPORTED_EXTS:
            results.append({
                'filename': filename,
                'error': f'ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ð°. ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‚ÑÑ: {", ".join(SUPPORTED_EXTS)}'
            })
            continue
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð° Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ
        file_path = TEMP_DIR / filename
        file.save(str(file_path))
        
        try:
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð°
            file_format = detect_format(file_path)
            if not file_format:
                results.append({
                    'filename': filename,
                    'error': 'ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ð°'
                })
                continue
            
            text = extract_text(file_path)
            if not text:
                results.append({
                    'filename': filename,
                    'error': 'ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°'
                })
                continue
            
            # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°
            embeddings = generate_embeddings_with_embedding_model(embedding_model, [text])
            results.append({
                'filename': filename,
                'format': file_format.upper(),
                'embedding': embeddings[0].tolist() if isinstance(embeddings[0], np.ndarray) else embeddings[0],
                'text_length': len(text),
                'vector_dimension': len(embeddings[0]) if isinstance(embeddings[0], (list, np.ndarray)) else 0
            })
        except Exception as e:
            results.append({
                'filename': filename,
                'error': f'ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {str(e)}'
            })
        finally:
            # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°
            if file_path.exists():
                file_path.unlink()
    
    return jsonify({'results': results})

@app.route('/start_cache_processing', methods=['POST'])
def start_cache_processing():
    """Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÐºÑÑˆÐ° Ð² Ñ„Ð¾Ð½Ð¾Ð²Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ"""
    global cache_processing_status
    if cache_processing_status['status'] == 'processing':
        return jsonify({'success': False, 'message': 'ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÐºÑÑˆÐ° ÑƒÐ¶Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð°'})
    
    if 'cache_file' not in request.files:
        return jsonify({'success': False, 'message': 'Ð¤Ð°Ð¹Ð» ÐºÑÑˆÐ° Ð½Ðµ Ð±Ñ‹Ð» Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½'}), 400
    
    cache_file = request.files['cache_file']
    if cache_file.filename == '':
        return jsonify({'success': False, 'message': 'ÐÐµ Ð²Ñ‹Ð±Ñ€Ð°Ð½ Ñ„Ð°Ð¹Ð» ÐºÑÑˆÐ°'}), 400
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ ÐºÑÑˆÐ°, ÐµÑÐ»Ð¸ Ð¾Ð½Ð° Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» ÐºÑÑˆÐ° Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ
    cache_path = CACHE_DIR / secure_filename(cache_file.filename)
    cache_file.save(str(cache_path))
    
    # ÐŸÑƒÑ‚ÑŒ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°
    output_path = CACHE_DIR / 'embeddings_cache.pkl'
    
    # Ð¡Ð±Ñ€Ð¾Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°
    cache_processing_status.update({
        'status': 'idle',
        'progress': 0,
        'current_file': '',
        'total_files': 0,
        'processed': 0,
        'result_path': '',
        'error_message': '',
        'start_time': 0,
        'end_time': 0
    })
    
    # Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
    threading.Thread(
        target=process_cache_embeddings_worker,
        args=(cache_path, output_path),
        daemon=True
    ).start()
    
    return jsonify({'success': True})

@app.route('/cache_status')
def get_cache_status():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÐºÑÑˆÐ°"""
    global cache_processing_status
    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ð¾Ð³Ð¾ Ð¾ÑÑ‚Ð°Ð²ÑˆÐµÐ³Ð¾ÑÑ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
    remaining_time = "-"
    if cache_processing_status['status'] == 'processing' and cache_processing_status['start_time'] > 0 and cache_processing_status['processed'] > 0:
        elapsed = time.time() - cache_processing_status['start_time']
        files_per_sec = cache_processing_status['processed'] / elapsed if elapsed > 0 else 0
        remaining_files = cache_processing_status['total_files'] - cache_processing_status['processed']
        if files_per_sec > 0:
            remaining_seconds = remaining_files / files_per_sec
            if remaining_seconds < 60:
                remaining_time = f"{int(remaining_seconds)} ÑÐµÐº"
            else:
                remaining_time = f"{int(remaining_seconds/60)} Ð¼Ð¸Ð½"
    return jsonify({
        'status': cache_processing_status['status'],
        'progress': cache_processing_status['progress'],
        'current_file': cache_processing_status['current_file'],
        'total_files': cache_processing_status['total_files'],
        'processed': cache_processing_status['processed'],
        'remaining_time': remaining_time,
        'result_path': cache_processing_status['result_path'],
        'error_message': cache_processing_status['error_message'],
        'start_time': cache_processing_status['start_time'],
        'end_time': cache_processing_status['end_time']
    })

@app.route('/download_embeddings_cache')
def download_embeddings_cache():
    """Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð¾Ð³Ð¾ ÐºÑÑˆÐ° ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²"""
    global cache_processing_status
    if cache_processing_status['status'] != 'completed' or not cache_processing_status['result_path']:
        return jsonify({'error': 'ÐÐµÑ‚ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð»Ñ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ'}), 404
    
    try:
        return send_file(
            cache_processing_status['result_path'],
            as_attachment=True,
            download_name='embeddings_cache.pkl',
            mimetype='application/octet-stream'
        )
    except Exception as e:
        return jsonify({'error': f'ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°: {str(e)}'}), 500

@app.route('/status')
def status():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° ÑÐµÑ€Ð²Ð¸ÑÐ°"""
    global cache_processing_status
    return jsonify({
        "status": "online",
        "model": EMBEDDING_MODEL,
        "device": device,
        "cache_processing": cache_processing_status['status'],
        "timestamp": time.time()
    })

def open_browser():
    """ÐžÑ‚ÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€ Ð¿Ð¾ÑÐ»Ðµ Ð·Ð°Ð¿ÑƒÑÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°"""
    time.sleep(1)  # Ð–Ð´ÐµÐ¼, Ð¿Ð¾ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑÑ
    webbrowser.open(f'http://{EMBEDDING_HOST}:{EMBEDDING_PORT}')

def show_help():
    """ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ Ð¿Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°"""
    print(f"""
ðŸ“š Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ñ Ð²ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ¾Ð¼ (BAAI/bge-m3)
Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:
  python app.py
ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ:
  ÐœÐ¾Ð´ÐµÐ»ÑŒ = {EMBEDDING_MODEL}
  Ð’ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€: http://{EMBEDDING_HOST}:{EMBEDDING_PORT}
ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹ Ñ„Ð°Ð¹Ð»Ð¾Ð²:
  {', '.join(SUPPORTED_EXTS)}
ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ„Ð°Ð¹Ð»Ð°: {MAX_FILE_SIZE / (1024*1024)} ÐœÐ‘
Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ: {TEMP_DIR}
ÐšÑÑˆ-Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ: {CACHE_DIR}
ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ BAAI/bge-m3:
  â€¢ Ð Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð²: 1024
  â€¢ ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð»Ð¸Ð½Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸: 8192 Ñ‚Ð¾ÐºÐµÐ½Ð°
  â€¢ ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° 100+ ÑÐ·Ñ‹ÐºÐ¾Ð²
Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ:
  â€¢ Ð¡ÐµÑ€Ð²ÐµÑ€ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸ Ð¾Ñ‚ÐºÑ€Ð¾ÐµÑ‚ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€
  â€¢ Ð”Ð»Ñ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ ÑÐµÑ€Ð²ÐµÑ€Ð° Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ctrl+C Ð² ÐºÐ¾Ð½ÑÐ¾Ð»Ð¸
    """)

if __name__ == '__main__':
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ñ… Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹ Ð´Ð»Ñ mobi Ð¸ epub
    try:
        import ebooklib
        from ebooklib import epub
        print("âœ… ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° EPUB Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°")
    except ImportError:
        print("âš ï¸ Ð‘Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ° ebooklib Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ: pip install EbookLib")
    
    try:
        import mobi
        print("âœ… ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° MOBI Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°")
    except ImportError:
        print("âš ï¸ Ð‘Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ° mobi Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ: pip install mobi")
    
    # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ
    show_help()
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº Ð´Ð»Ñ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð°
    browser_thread = threading.Thread(target=open_browser)
    browser_thread.daemon = True
    browser_thread.start()
    
    # Ð—Ð°Ð¿ÑƒÑÐº Flask Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
    print(f"""
ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð° ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð½Ð° http://{EMBEDDING_HOST}:{EMBEDDING_PORT}""")
    print("Ð”Ð»Ñ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ ÑÐµÑ€Ð²ÐµÑ€Ð° Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ctrl+C Ð² ÐºÐ¾Ð½ÑÐ¾Ð»Ð¸")
    try:
        app.run(host=EMBEDDING_HOST, port=EMBEDDING_PORT, debug=False, use_reloader=False)
    except KeyboardInterrupt:
        print("""
ðŸ›‘ Ð¡ÐµÑ€Ð²ÐµÑ€ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼""")
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ ÑÐµÑ€Ð²ÐµÑ€Ð°: {str(e)}")
        sys.exit(1)