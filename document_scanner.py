import os
import sys
import time
import hashlib
import pickle
import json
import threading
import webbrowser
from pathlib import Path
from flask import Flask, render_template, request, jsonify
from tqdm import tqdm

# –ò–º–ø–æ—Ä—Ç –∏–∑ –æ–±—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from config import SCANNER_HOST, SCANNER_PORT, INDEX_DIR, DEFAULT_ROOT_DIR, MIN_FILE_SIZE, MAX_TEXT_LEN, USE_CACHE, SUPPORTED_EXTS, SCAN_CACHE_FILE
from document_processor import detect_format, extract_text, get_file_hash, is_valid_file, clean_text

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
scan_status = {
    'status': 'idle',  # idle, scanning, completed, error
    'progress': 0,
    'current_file': '',
    'total_files': 0,
    'processed': 0,
    'skipped_small': 0,
    'skipped_empty': 0,
    'skipped_dupes': 0,
    'result_path': '',
    'error_message': '',
    'start_time': 0,
    'end_time': 0
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = Flask(__name__, template_folder='./templates')

def load_scan_cache(index_dir):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
    scan_cache_path = Path(index_dir) / SCAN_CACHE_FILE
    if not scan_cache_path.exists():
        return None
    try:
        with open(scan_cache_path, 'rb') as f:
            return pickle.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫—ç—à–∞: {str(e)}")
        return None

def scan_documents(root_dir, index_dir, min_file_size, max_text_len, use_cache):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    global scan_status
    try:
        root = Path(root_dir)
        index_path = Path(index_dir)
        if not root.is_dir():
            raise Exception(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {root_dir}")
        index_path.mkdir(parents=True, exist_ok=True)
        scan_cache_path = index_path / SCAN_CACHE_FILE
        
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        supported_exts = SUPPORTED_EXTS
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        scan_status.update({
            'status': 'scanning',
            'start_time': time.time(),
            'error_message': ''
        })
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫—ç—à–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        scan_cache = load_scan_cache(index_dir) if use_cache else None
        
        # –°–±–æ—Ä –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ —Å –ø–æ–¥—Ö–æ–¥—è—â–∏–º–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏
        all_files = []
        for ext in supported_exts:
            all_files.extend(root.rglob(f'*{ext}'))
        scan_status['total_files'] = len(all_files)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
        files_to_process = all_files
        removed_files = []
        doc_paths = []
        texts = []
        seen_hashes = set()
        
        if scan_cache and use_cache:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞
            doc_paths = scan_cache['doc_paths'][:]
            texts = scan_cache['texts'][:]
            seen_hashes = set(scan_cache['seen_hashes'])
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            cached_paths = set(scan_cache['doc_paths'])
            cached_mtimes = {}
            for path in scan_cache['doc_paths']:
                p = Path(path)
                if p.exists():
                    cached_mtimes[path] = p.stat().st_mtime
            
            files_to_add = []
            files_to_recheck = []
            for file_path in all_files:
                str_path = str(file_path)
                if str_path not in cached_paths:
                    files_to_add.append(file_path)
                elif str_path in cached_mtimes:
                    current_mtime = file_path.stat().st_mtime
                    if current_mtime > cached_mtimes[str_path] + 1:
                        files_to_recheck.append(file_path)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            removed_files = [path for path in cached_paths if not Path(path).exists()]
            for removed_path in removed_files:
                if removed_path in doc_paths:
                    idx = doc_paths.index(removed_path)
                    doc_paths.pop(idx)
                    texts.pop(idx)
            
            files_to_process = files_to_add + files_to_recheck
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        processed_count = 0
        skipped_small = 0
        skipped_empty = 0
        skipped_dupes = 0
        scan_status.update({
            'processed': 0,
            'skipped_small': 0,
            'skipped_empty': 0,
            'skipped_dupes': 0,
            'current_file': ''
        })
        
        for i, file_path in enumerate(files_to_process):
            if scan_status['status'] != 'scanning':
                break
            scan_status['current_file'] = str(file_path.relative_to(root))
            scan_status['progress'] = int((i + 1) / max(1, len(files_to_process)) * 100)
            
            if not file_path.is_file():
                continue
            
            file_size = file_path.stat().st_size
            # –ü—Ä–æ–ø—É—Å–∫ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
            if file_size < min_file_size:
                skipped_small += 1
                scan_status['skipped_small'] = skipped_small
                continue
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text = extract_text(file_path)
            if not text:
                skipped_empty += 1
                scan_status['skipped_empty'] = skipped_empty
                continue
            
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
            text = clean_text(text)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
            digest = get_file_hash(text)
            if digest in seen_hashes:
                skipped_dupes += 1
                scan_status['skipped_dupes'] = skipped_dupes
                continue
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            seen_hashes.add(digest)
            doc_paths.append(str(file_path))
            texts.append(text[:max_text_len])
            processed_count += 1
            scan_status['processed'] = processed_count
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞
        stats = {
            'processed': processed_count,
            'skipped_small': skipped_small,
            'skipped_empty': skipped_empty,
            'skipped_dupes': skipped_dupes,
            'total_docs': len(doc_paths),
            'removed_files': len(removed_files)
        }
        
        cache_data = {
            'doc_paths': doc_paths,
            'texts': texts,
            'seen_hashes': list(seen_hashes),
            'stats': stats,
            'timestamp': time.time()
        }
        
        with open(scan_cache_path, 'wb') as f:
            pickle.dump(cache_data, f)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é
        scan_status.update({
            'status': 'completed',
            'end_time': time.time(),
            'result_path': str(scan_cache_path),
            'processed': processed_count,
            'skipped_small': skipped_small,
            'skipped_empty': skipped_empty,
            'skipped_dupes': skipped_dupes,
            'progress': 100
        })
        
        print(f"‚úÖ –ö—ç—à —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {scan_cache_path}")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: –º–µ–ª–∫–∏—Ö-{skipped_small}, –ø—É—Å—Ç—ã—Ö-{skipped_empty}, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤-{skipped_dupes}")
        return scan_cache_path
    except Exception as e:
        scan_status.update({
            'status': 'error',
            'error_message': str(e),
            'end_time': time.time()
        })
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏: {str(e)}")
        raise

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
    return render_template(
        'scanner.html',
        default_root_dir=str(DEFAULT_ROOT_DIR),
        index_dir=str(INDEX_DIR),
        min_file_size_kb=MIN_FILE_SIZE / 1024,
        max_text_len=MAX_TEXT_LEN,
        use_cache=USE_CACHE,
        supported_exts=SUPPORTED_EXTS,
        port=SCANNER_PORT,
        current_year=time.localtime().tm_year
    )

@app.route('/start_scan', methods=['POST'])
def start_scan():
    """–ó–∞–ø—É—Å–∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
    global scan_status
    if scan_status['status'] == 'scanning':
        return jsonify({'success': False, 'message': '–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ'})
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ —Ñ–æ—Ä–º—ã
    try:
        root_dir = request.form.get('root_dir', str(DEFAULT_ROOT_DIR))
        index_dir = request.form.get('index_dir', str(INDEX_DIR))
        min_file_size = int(float(request.form.get('min_file_size', MIN_FILE_SIZE/1024)) * 1024)
        max_text_len = int(request.form.get('max_text_len', MAX_TEXT_LEN))
        use_cache = 'use_cache' in request.form
        
        # –°–±—Ä–æ—Å —Å—Ç–∞—Ç—É—Å–∞
        scan_status.update({
            'status': 'idle',
            'progress': 0,
            'current_file': '',
            'total_files': 0,
            'processed': 0,
            'skipped_small': 0,
            'skipped_empty': 0,
            'skipped_dupes': 0,
            'result_path': '',
            'error_message': '',
            'start_time': 0,
            'end_time': 0
        })
        
        # –ó–∞–ø—É—Å–∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        threading.Thread(
            target=scan_wrapper,
            args=(root_dir, index_dir, min_file_size, max_text_len, use_cache),
            daemon=True
        ).start()
        
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö: {str(e)}'})

def scan_wrapper(root_dir, index_dir, min_file_size, max_text_len, use_cache):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –≤ –ø–æ—Ç–æ–∫–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
    global scan_status
    try:
        scan_documents(root_dir, index_dir, min_file_size, max_text_len, use_cache)
    except Exception as e:
        scan_status.update({
            'status': 'error',
            'error_message': str(e),
            'end_time': time.time()
        })

@app.route('/scan_status')
def get_scan_status():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
    global scan_status
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω–æ–≥–æ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏
    remaining_time = "-"
    if scan_status['status'] == 'scanning' and scan_status['start_time'] > 0 and scan_status['processed'] > 0:
        elapsed = time.time() - scan_status['start_time']
        files_per_sec = scan_status['processed'] / elapsed if elapsed > 0 else 0
        remaining_files = scan_status['total_files'] - scan_status['processed']
        if files_per_sec > 0:
            remaining_seconds = remaining_files / files_per_sec
            if remaining_seconds < 60:
                remaining_time = f"{int(remaining_seconds)} —Å–µ–∫"
            else:
                remaining_time = f"{int(remaining_seconds/60)} –º–∏–Ω"
    return jsonify({
        'status': scan_status['status'],
        'progress': scan_status['progress'],
        'current_file': scan_status['current_file'],
        'total_files': scan_status['total_files'],
        'processed': scan_status['processed'],
        'skipped_small': scan_status['skipped_small'],
        'skipped_empty': scan_status['skipped_empty'],
        'skipped_dupes': scan_status['skipped_dupes'],
        'remaining_time': remaining_time,
        'result_path': scan_status['result_path'],
        'error_message': scan_status['error_message'],
        'start_time': scan_status['start_time'],
        'end_time': scan_status['end_time']
    })

@app.route('/stop_scan', methods=['POST'])
def stop_scan():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
    global scan_status
    if scan_status['status'] == 'scanning':
        scan_status['status'] = 'stopping'
        return jsonify({'success': True, 'message': '–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...'})
    return jsonify({'success': False, 'message': '–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ'})

def show_help():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø—Ä–∞–≤–∫—É –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–∫—Ä–∏–ø—Ç–∞"""
    print(f"""
üìö –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫—ç—à–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python app.py
–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DEFAULT_ROOT_DIR}
  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {INDEX_DIR}
  –í–µ–±-—Å–µ—Ä–≤–µ—Ä: http://{SCANNER_HOST}:{SCANNER_PORT}
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤:
  {', '.join(SUPPORTED_EXTS)}
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {MIN_FILE_SIZE / 1024} –ö–ë
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {MAX_TEXT_LEN} —Å–∏–º–≤–æ–ª–æ–≤
–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:
  ‚Ä¢ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏ –æ—Ç–∫—Ä–æ–µ—Ç –±—Ä–∞—É–∑–µ—Ä
  ‚Ä¢ –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C –≤ –∫–æ–Ω—Å–æ–ª–∏
    """)

def open_browser():
    """–û—Ç–∫—Ä—ã–≤–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"""
    time.sleep(1)  # –ñ–¥–µ–º, –ø–æ–∫–∞ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è
    webbrowser.open(f'http://{SCANNER_HOST}:{SCANNER_PORT}')

if __name__ == '__main__':
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è mobi –∏ epub
    try:
        import ebooklib
        from ebooklib import epub
        print("‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ EPUB –¥–æ—Å—Ç—É–ø–Ω–∞")
    except ImportError:
        print("‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ ebooklib –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ü–æ–¥–¥–µ—Ä–∂–∫–∞ EPUB –±—É–¥–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞.")
    
    try:
        import mobi
        print("‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ MOBI –¥–æ—Å—Ç—É–ø–Ω–∞")
    except ImportError:
        print("‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ mobi –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ü–æ–¥–¥–µ—Ä–∂–∫–∞ MOBI –±—É–¥–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞.")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø—Ä–∞–≤–∫—É
    show_help()
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –±—Ä–∞—É–∑–µ—Ä–∞
    browser_thread = threading.Thread(target=open_browser)
    browser_thread.daemon = True
    browser_thread.start()
    
    # –ó–∞–ø—É—Å–∫ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    print(f"""
üöÄ –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ —Å–∫–∞–Ω–µ—Ä–∞ –Ω–∞ http://{SCANNER_HOST}:{SCANNER_PORT}""")
    print("–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C –≤ –∫–æ–Ω—Å–æ–ª–∏")
    try:
        app.run(host=SCANNER_HOST, port=SCANNER_PORT, debug=False, use_reloader=False)
    except KeyboardInterrupt:
        print("""
üõë –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º""")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")
        sys.exit(1)